"""
An√°lise de Canal do YouTube - Vers√£o Streamlit
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from youtube_analytics import YouTubeAnalytics
from sklearn.linear_model import LinearRegression

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise do Canal Let's Media Oficia",
    page_icon="üìä",
    layout="wide"
)

# Configura√ß√£o da API
API_KEY = 'AIzaSyCswbMKKorlHVSA_9kWSS9ZIKogaurZdNA'

# T√≠tulo principal
st.title("An√°lise do Canal Let's Media Oficia")

try:
    # Inicializa√ß√£o da classe de an√°lise usando busca direta
    @st.cache_resource
    def get_analyzer():
        analyzer = YouTubeAnalytics(API_KEY)
        # Busca o canal pelo nome exato
        channel_id = analyzer.search_channel_by_name("Let's Media Oficia")
        if channel_id:
            analyzer.channel_id = channel_id
            return analyzer
        else:
            st.error("Canal n√£o encontrado via busca por nome. Tentando URL alternativa...")
            # Tenta usar o URL como fallback
            return YouTubeAnalytics(API_KEY, channel_url='https://www.youtube.com/@LetsMediaOficia')

    analyzer = get_analyzer()

    # Verifica se o canal foi encontrado
    @st.cache_data(ttl=3600)
    def get_channel_info():
        return analyzer.get_channel_info()

    channel_info = get_channel_info()

    if not channel_info:
        st.error("Canal n√£o encontrado. Verifique a URL ou ID do canal.")
        st.info("Tente procurar o canal manualmente em https://www.youtube.com e copiar a URL exata.")
        st.stop()

    # Obten√ß√£o dos dados hist√≥ricos a partir dos v√≠deos
    @st.cache_data(ttl=3600)
    def get_videos_data(video_count=100):
        return analyzer.get_channel_historical_data(video_count=video_count)

    df_videos = get_videos_data()

    # Fun√ß√£o para prever crescimento de visualiza√ß√µes usando regress√£o linear
    def predict_views_growth(df, days=30):
        if df is None or len(df) < 10:
            return None
        
        # Preparar dados para previs√£o
        df_sorted = df.sort_values('publishedAt')
        
        # Criar s√©rie temporal agregada por dia
        df_sorted['date'] = df_sorted['publishedAt'].dt.date
        df_daily = df_sorted.groupby('date')['viewCount'].sum().reset_index()
        df_daily['date'] = pd.to_datetime(df_daily['date'])
        
        # Preencher datas faltantes e criar s√©rie cont√≠nua
        date_range = pd.date_range(start=df_daily['date'].min(), end=df_daily['date'].max())
        full_df = pd.DataFrame({'date': date_range})
        full_df = pd.merge(full_df, df_daily, on='date', how='left')
        full_df['viewCount'] = full_df['viewCount'].fillna(0)
        
        # Calcular visualiza√ß√µes cumulativas
        full_df['cumulative_views'] = full_df['viewCount'].cumsum()
        
        # Preparar dados para regress√£o linear
        X = np.arange(len(full_df)).reshape(-1, 1)
        y = full_df['cumulative_views'].values
        
        # Treinar modelo de regress√£o linear
        model = LinearRegression()
        model.fit(X, y)
        
        # Preparar datas para previs√£o
        future_dates = pd.date_range(
            start=full_df['date'].max() + timedelta(days=1),
            periods=days
        )
        
        # Prever valores futuros
        future_X = np.arange(len(full_df), len(full_df) + days).reshape(-1, 1)
        future_y = model.predict(future_X)
        
        # Criar dataframe com resultados
        forecast_df = pd.DataFrame({
            'ds': pd.concat([full_df['date'], pd.Series(future_dates)]),
            'y': np.concatenate([full_df['cumulative_views'].values, future_y]),
            'yhat': np.concatenate([full_df['cumulative_views'].values, future_y]),
            'yhat_lower': np.concatenate([
                full_df['cumulative_views'].values, 
                future_y * 0.9  # Limite inferior simples: -10%
            ]),
            'yhat_upper': np.concatenate([
                full_df['cumulative_views'].values, 
                future_y * 1.1  # Limite superior simples: +10%
            ])
        })
        
        return forecast_df

    # Layout do Dashboard
    col1, col2 = st.columns([1, 2])

    # Coluna 1: Informa√ß√µes do Canal
    with col1:
        st.subheader("Informa√ß√µes do Canal")
        st.metric("Inscritos", f"{channel_info['subscriberCount']:,}")
        st.metric("Total de Visualiza√ß√µes", f"{channel_info['viewCount']:,}")
        st.metric("Total de V√≠deos", f"{channel_info['videoCount']:,}")
        st.write(f"**Data de Cria√ß√£o:** {datetime.fromisoformat(channel_info['publishedAt'].replace('Z', '+00:00')).strftime('%d/%m/%Y')}")

    # Coluna 2: M√©tricas de Engajamento
    with col2:
        st.subheader("M√©tricas de Engajamento")
        
        if df_videos is not None and len(df_videos) > 0:
            # Calcula taxas de engajamento m√©dias
            avg_views = df_videos['viewCount'].mean()
            avg_likes = df_videos['likeCount'].mean()
            avg_comments = df_videos['commentCount'].mean()
            
            engagement_rate = (avg_likes + avg_comments) / avg_views * 100 if avg_views > 0 else 0
            like_rate = avg_likes / avg_views * 100 if avg_views > 0 else 0
            comment_rate = avg_comments / avg_views * 100 if avg_views > 0 else 0
            
            engagement_col1, engagement_col2, engagement_col3 = st.columns(3)
            
            with engagement_col1:
                st.metric("Taxa de Engajamento", f"{engagement_rate:.2f}%")
                st.metric("Visualiza√ß√µes M√©dias", f"{avg_views:.0f}")
            
            with engagement_col2:
                st.metric("Taxa de Likes", f"{like_rate:.2f}%")
                st.metric("Likes M√©dios", f"{avg_likes:.0f}")
                
            with engagement_col3:
                st.metric("Taxa de Coment√°rios", f"{comment_rate:.2f}%")
                st.metric("Coment√°rios M√©dios", f"{avg_comments:.0f}")
        else:
            st.warning("Dados insuficientes para calcular m√©tricas de engajamento.")

    # Visualiza√ß√µes por V√≠deo
    st.subheader("Visualiza√ß√µes por V√≠deo")
    if df_videos is not None and len(df_videos) > 0:
        # Seleciona os √∫ltimos 20 v√≠deos para visualiza√ß√£o
        df_recent = df_videos.sort_values('publishedAt', ascending=False).head(20)
        
        fig = px.bar(df_recent, x='title', y='viewCount', 
                    labels={'viewCount': 'Visualiza√ß√µes', 'title': 'T√≠tulo do V√≠deo'},
                    title='Visualiza√ß√µes por V√≠deo (20 mais recentes)')
        
        fig.update_layout(
            xaxis={'categoryorder': 'total descending'},
            xaxis_tickangle=-45,
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Dados insuficientes para mostrar visualiza√ß√µes por v√≠deo.")

    # Crescimento ao Longo do Tempo
    st.subheader("Crescimento ao Longo do Tempo")
    if df_videos is not None and len(df_videos) > 0:
        # Cria uma c√≥pia para evitar o aviso de SettingWithCopyWarning
        df_for_growth = df_videos.copy()
        
        # Agrupa os v√≠deos por m√™s e soma as visualiza√ß√µes
        df_for_growth['month'] = df_for_growth['publishedAt'].dt.to_period('M')
        monthly_data = df_for_growth.groupby('month').agg({
            'viewCount': 'sum',
            'likeCount': 'sum',
            'commentCount': 'sum',
            'id': 'count'
        }).reset_index()
        
        monthly_data['month'] = monthly_data['month'].dt.to_timestamp()
        
        # Cria o gr√°fico de crescimento
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=monthly_data['month'], 
            y=monthly_data['viewCount'],
            mode='lines+markers',
            name='Visualiza√ß√µes',
            line=dict(width=3)
        ))
        
        fig.add_trace(go.Scatter(
            x=monthly_data['month'], 
            y=monthly_data['id'] * 1000,  # Multiplica√ß√£o para escala
            mode='lines+markers',
            name='V√≠deos Publicados (x1000)',
            line=dict(width=2, dash='dot')
        ))
        
        fig.update_layout(
            title='Crescimento Mensal de Visualiza√ß√µes',
            xaxis_title='M√™s',
            yaxis_title='Visualiza√ß√µes',
            height=500,
            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Dados insuficientes para mostrar crescimento ao longo do tempo.")

    # Previs√£o de Crescimento
    st.subheader("Previs√£o de Crescimento")
    if df_videos is not None and len(df_videos) >= 10:
        try:
            # Prever crescimento para os pr√≥ximos 90 dias
            forecast = predict_views_growth(df_videos, days=90)
            
            if forecast is not None:
                fig = go.Figure()
                
                # Dados hist√≥ricos
                historical = df_videos.sort_values('publishedAt')
                historical_idx = len(historical)
                
                # Adiciona dados hist√≥ricos
                fig.add_trace(go.Scatter(
                    x=forecast['ds'][:historical_idx],
                    y=forecast['y'][:historical_idx],
                    mode='lines',
                    name='Visualiza√ß√µes Hist√≥ricas',
                    line=dict(width=2)
                ))
                
                # Adiciona previs√£o
                fig.add_trace(go.Scatter(
                    x=forecast['ds'][historical_idx:],
                    y=forecast['yhat'][historical_idx:],
                    mode='lines',
                    name='Previs√£o',
                    line=dict(width=3, dash='dash', color='red')
                ))
                
                # Adiciona intervalo de confian√ßa
                fig.add_trace(go.Scatter(
                    x=forecast['ds'][historical_idx:],
                    y=forecast['yhat_upper'][historical_idx:],
                    mode='lines',
                    name='Limite Superior',
                    line=dict(width=0),
                    showlegend=False
                ))
                
                fig.add_trace(go.Scatter(
                    x=forecast['ds'][historical_idx:],
                    y=forecast['yhat_lower'][historical_idx:],
                    mode='lines',
                    name='Limite Inferior',
                    line=dict(width=0),
                    fill='tonexty',
                    fillcolor='rgba(255, 0, 0, 0.1)',
                    showlegend=False
                ))
                
                fig.update_layout(
                    title='Previs√£o de Crescimento de Visualiza√ß√µes (90 dias)',
                    xaxis_title='Data',
                    yaxis_title='Visualiza√ß√µes Acumuladas',
                    height=500,
                    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("N√£o foi poss√≠vel gerar previs√µes de crescimento com os dados dispon√≠veis.")
        except Exception as e:
            st.error(f"Erro na previs√£o de crescimento: {e}")
    else:
        st.warning("Dados insuficientes para fazer previs√µes de crescimento.")

    # V√≠deos com Maior Engajamento
    st.subheader("V√≠deos com Maior Engajamento")
    if df_videos is not None and len(df_videos) > 0:
        # Calcula a taxa de engajamento para cada v√≠deo
        df_for_engagement = df_videos.copy()
        df_for_engagement['engagement_rate'] = (df_for_engagement['likeCount'] + df_for_engagement['commentCount']) / df_for_engagement['viewCount'] * 100
        
        # Seleciona os 10 v√≠deos com maior engajamento
        top_videos = df_for_engagement.sort_values('engagement_rate', ascending=False).head(10)
        
        # Cria uma tabela formatada com Streamlit
        st.dataframe(
            top_videos[['title', 'viewCount', 'likeCount', 'commentCount', 'engagement_rate']].rename(
                columns={
                    'title': 'T√≠tulo', 
                    'viewCount': 'Visualiza√ß√µes', 
                    'likeCount': 'Likes', 
                    'commentCount': 'Coment√°rios', 
                    'engagement_rate': 'Taxa de Engajamento (%)'
                }
            ).style.format({
                'Visualiza√ß√µes': '{:,}',
                'Likes': '{:,}',
                'Coment√°rios': '{:,}',
                'Taxa de Engajamento (%)': '{:.2f}%'
            }),
            use_container_width=True
        )
    else:
        st.warning("Dados insuficientes para mostrar v√≠deos com maior engajamento.")

    # Canais Similares
    st.subheader("Canais Similares")
    similar_channels = analyzer.search_similar_channels(max_results=5)

    if similar_channels:
        # Cria colunas para mostrar os canais similares
        channel_cols = st.columns(len(similar_channels))
        
        for i, channel in enumerate(similar_channels):
            with channel_cols[i]:
                st.write(f"**{channel['title']}**")
                st.write(channel['description'][:200] + "..." if len(channel['description']) > 200 else channel['description'])
                st.write(f"[Visitar Canal](https://www.youtube.com/channel/{channel['id']})")
    else:
        st.warning("Nenhum canal similar encontrado.")
except Exception as e:
    st.error(f"Erro ao inicializar a aplica√ß√£o: {e}")
    st.info("Detalhes do erro para ajudar na depura√ß√£o:")
    st.exception(e) 